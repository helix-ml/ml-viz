{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# code from https://medium.com/district-data-labs/building-a-classifier-from-census-data-18f996c4d7cf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# prepare train and test data\n",
    "names = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income',\n",
    "]\n",
    "data = pd.read_csv('census_data/adult.data', names=names)\n",
    "\n",
    "import json\n",
    "meta = {\n",
    "    'target_names': list(data.income.unique()),\n",
    "    'feature_names': list(data.columns),\n",
    "    'categorical_features': {\n",
    "        column: list(data[column].unique())\n",
    "        for column in data.columns\n",
    "        if data[column].dtype == 'object'\n",
    "    },\n",
    "}\n",
    "with open('census_data/meta.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "    \n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def load_data():\n",
    "    # Load the meta data from the file\n",
    "    with open('census_data/meta.json', 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    names = meta['feature_names']\n",
    "    # Load the training and test data, skipping the bad row in the test data\n",
    "    train = pd.read_csv('census_data/adult.data', names=names)\n",
    "    test  = pd.read_csv('census_data/adult.test', names=names, skiprows=1)\n",
    "    # Remove the target from the categorical features\n",
    "    meta['categorical_features'].pop('income')\n",
    "    # Return the bunch with the appropriate data chunked apart\n",
    "    return Bunch(\n",
    "        data = train[names[:-1]],\n",
    "        target = train[names[-1]],\n",
    "        data_test = test[names[:-1]],\n",
    "        target_test = test[names[-1]],\n",
    "        target_names = meta['target_names'],\n",
    "        feature_names = meta['feature_names'],\n",
    "        categorical_features = meta['categorical_features'],\n",
    "        DESCR = \"descr\",\n",
    "    )\n",
    "dataset = load_data()\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns  = columns\n",
    "        self.encoders = None\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to encode.\n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "        # Fit a label encoder for each column in the data frame\n",
    "        self.encoders = {\n",
    "            column: LabelEncoder().fit(data[column])\n",
    "            for column in self.columns\n",
    "        }\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame.\n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        for column, encoder in self.encoders.items():\n",
    "            output[column] = encoder.transform(data[column])\n",
    "        return output\n",
    "encoder = EncodeCategorical(dataset.categorical_features.keys())\n",
    "dataset.data = encoder.fit_transform(dataset.data)\n",
    "dataset.data_test = encoder.fit_transform(dataset.data_test)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "class ImputeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.imputer = None\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to impute.\n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "        # Fit an imputer for each column in the data frame\n",
    "        self.imputer = SimpleImputer(missing_values=0, strategy='most_frequent')\n",
    "        self.imputer.fit(data[self.columns])\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame.\n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        output[self.columns] = self.imputer.transform(output[self.columns])\n",
    "        return output\n",
    "imputer = ImputeCategorical(['workclass', 'native-country', 'occupation'])\n",
    "dataset.data = imputer.fit_transform(dataset.data)\n",
    "dataset.data_test = imputer.fit_transform(dataset.data_test)\n",
    "\n",
    "X_train = dataset.data\n",
    "yencode = LabelEncoder().fit(dataset.target)\n",
    "y_train = yencode.transform(dataset.target)\n",
    "\n",
    "X_test = dataset.data_test\n",
    "y_test = yencode.transform([y.rstrip(\".\") for y in dataset.target_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8090/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x120856cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[1;32m~/Documents/GitHub/ml-viz/ml-viz/davincicode/DaVinciCode.py\u001b[0m in \u001b[0;36mupdate_pc\u001b[1;34m(\n",
      "    clickData='main/MLPClassifier/max_iter=nan/',\n",
      "    rangeData=[0, 1],\n",
      "    n=242\n",
      ")\u001b[0m\n",
      "\u001b[0;32m    428\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    429\u001b[0m                         \u001b[0mselected_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 430\u001b[1;33m                 \u001b[0msample_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m        \u001b[0;36msample_vals\u001b[0m \u001b[1;34m= \u001b[1;36mundefined\u001b[0m\u001b[0m\u001b[1;34m\n",
      "        \u001b[0m\u001b[0;36mselected_df.iloc\u001b[0m \u001b[1;34m= <pandas.core.indexing._iLocIndexer object at 0x120aacb38>\u001b[0m\n",
      "\u001b[0;32m    431\u001b[0m                 \u001b[0mlabels_pc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    432\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhierarchy_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubset_counter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(\n",
      "    self=<pandas.core.indexing._iLocIndexer object>,\n",
      "    key=0\n",
      ")\u001b[0m\n",
      "\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m        \u001b[0;36mself._getitem_axis\u001b[0m \u001b[1;34m= <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object at 0x1297a7ef8>>\u001b[0m\u001b[1;34m\n",
      "        \u001b[0m\u001b[0;36mmaybe_callable\u001b[0m \u001b[1;34m= 0\u001b[0m\u001b[1;34m\n",
      "        \u001b[0m\u001b[0;36maxis\u001b[0m \u001b[1;34m= 0\u001b[0m\n",
      "\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(\n",
      "    self=<pandas.core.indexing._iLocIndexer object>,\n",
      "    key=0,\n",
      "    axis=0\n",
      ")\u001b[0m\n",
      "\u001b[0;32m   2136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   2137\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 2138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m        \u001b[0;36mself._validate_integer\u001b[0m \u001b[1;34m= <bound method _iLocIndexer._validate_integer of <pandas.core.indexing._iLocIndexer object at 0x1297a7ef8>>\u001b[0m\u001b[1;34m\n",
      "        \u001b[0m\u001b[0;36mkey\u001b[0m \u001b[1;34m= 0\u001b[0m\u001b[1;34m\n",
      "        \u001b[0m\u001b[0;36maxis\u001b[0m \u001b[1;34m= 0\u001b[0m\n",
      "\u001b[0;32m   2139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   2140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(\n",
      "    self=<pandas.core.indexing._iLocIndexer object>,\n",
      "    key=0,\n",
      "    axis=0\n",
      ")\u001b[0m\n",
      "\u001b[0;32m   2061\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   2062\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 2063\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m        \u001b[1;36mglobal\u001b[0m \u001b[0;36mIndexError\u001b[0m \u001b[1;34m= \u001b[1;36mundefined\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   2064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   2065\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from davincicode import DaVinciCode\n",
    "app = DaVinciCode(port=8090, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "app.experiment(library='sklearn', model=MLPClassifier, params = {\n",
    "    'max_iter': 100,\n",
    "    'alpha': 0.001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.experiment(library='sklearn', model=MLPClassifier, params = {\n",
    "    'max_iter': 400,\n",
    "    'alpha': 0.0001\n",
    "})\n",
    "\n",
    "app.experiment(library='sklearn', model=MLPClassifier, params = {\n",
    "    'max_iter': 400,\n",
    "    'alpha': 0.00001\n",
    "})\n",
    "\n",
    "app.experiment(library='sklearn', model=MLPClassifier, params = {\n",
    "    'max_iter': 200,\n",
    "    'alpha': 0.001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 2,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'max_depth': 10,\n",
    "        'min_child_weight': 10,\n",
    "        'eta':0.2,\n",
    "        'subsample': 0.05,\n",
    "        'colsample_bytree': 0.05\n",
    "}\n",
    "\n",
    "app.experiment(library='xgboost', model=None, params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 1\n",
    "params['min_child_weight'] = 6\n",
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 0.05\n",
    "params['eta'] = 0.15\n",
    "app.experiment('xgboost', None, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 10\n",
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 1.0\n",
    "app.experiment('xgboost', None, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "app.experiment('sklearn', SVC, {\n",
    "    'gamma': 0.01,\n",
    "    'C': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
